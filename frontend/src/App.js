import React, { useState, useEffect, useRef } from 'react';
import './App.css';
import { RealtimeClient } from '@openai/realtime-api-beta';

const BACKEND_URL = process.env.REACT_APP_BACKEND_URL || 'http://localhost:8001';

// Voice Mode RealtimeClient Class
class RealtimeAudioChat {
  constructor() {
    this.client = null;
    this.audioContext = null;
    this.audioWorkletNode = null;
    this.mediaStream = null;
    this.onStatusChange = null;
    this.onError = null;
    this.onMessage = null;
    this.isConnected = false;
  }

  async init() {
    try {
      console.log('üé§ [VOICE INIT] Starting Voice Mode initialization for –ê–ª–µ—Å—è...');
      console.log('üé§ [VOICE INIT] Backend URL:', BACKEND_URL);
      
      // Step 1: Get session from backend
      console.log('üé§ [VOICE INIT] Step 1: Requesting session from backend...');
      const tokenResponse = await fetch(`${BACKEND_URL}/api/voice/realtime/session`, {
        method: "POST",
        headers: {
          "Content-Type": "application/json"
        },
        body: JSON.stringify({
          voice: "shimmer", // Female voice for –ê–ª–µ—Å—è
          model: "gpt-4o-realtime-preview-2024-12-17"
        })
      });
      
      console.log('üé§ [VOICE INIT] Session response status:', tokenResponse.status);
      console.log('üé§ [VOICE INIT] Session response headers:', Object.fromEntries(tokenResponse.headers.entries()));
      
      if (!tokenResponse.ok) {
        const errorText = await tokenResponse.text();
        console.error('üé§ [VOICE INIT] Session request failed:', errorText);
        throw new Error(`Session request failed: ${tokenResponse.status} - ${errorText}`);
      }
      
      const data = await tokenResponse.json();
      console.log('üé§ [VOICE INIT] Session data received:', data);
      
      if (!data.client_secret) {
        console.error('üé§ [VOICE INIT] No client_secret in response:', data);
        throw new Error("Failed to get session token");
      }
      
      console.log('üé§ [VOICE INIT] Step 2: Initializing RealtimeClient...');
      // Initialize RealtimeClient with relay server
      this.client = new RealtimeClient({ 
        url: `${BACKEND_URL}/api/voice/realtime/ws`,
        dangerouslyAllowAPIKeyInBrowser: true
      });
      console.log('üé§ [VOICE INIT] RealtimeClient created successfully');

      // Set up event handlers
      console.log('üé§ [VOICE INIT] Step 3: Setting up event handlers...');
      this.setupEventHandlers();
      console.log('üé§ [VOICE INIT] Event handlers set up');

      // Configure session parameters
      console.log('üé§ [VOICE INIT] Step 4: Configuring session parameters...');
      this.client.updateSession({
        instructions: '–¢—ã –ê–ª–µ—Å—è - AI-–∞—Å—Å–∏—Å—Ç–µ–Ω—Ç –ø–æ –ö–æ–Ω—Å—Ç–∏—Ç—É—Ü–∏–∏ –†–µ—Å–ø—É–±–ª–∏–∫–∏ –ë–µ–ª–∞—Ä—É—Å—å. –û—Ç–≤–µ—á–∞–π –Ω–∞ –≤–æ–ø—Ä–æ—Å—ã —Å–æ–≥–ª–∞—Å–Ω–æ –ö–æ–Ω—Å—Ç–∏—Ç—É—Ü–∏–∏ –†–ë —Ä–µ–¥–∞–∫—Ü–∏–∏ 2022 –≥–æ–¥–∞. –ì–æ–≤–æ—Ä–∏ –¥—Ä—É–∂–µ–ª—é–±–Ω–æ –∏ –ø—Ä–æ—Ñ–µ—Å—Å–∏–æ–Ω–∞–ª—å–Ω–æ.',
        voice: 'shimmer',
        turn_detection: { type: 'server_vad' },
        input_audio_transcription: { model: 'whisper-1' },
        output_audio_format: 'pcm_16000'
      });
      console.log('üé§ [VOICE INIT] Session parameters configured');

      // Connect to Realtime API
      console.log('üé§ [VOICE INIT] Step 5: Connecting to Realtime API...');
      await this.client.connect();
      console.log('üé§ [VOICE INIT] Connected to Realtime API successfully');
      
      // Set up audio processing
      console.log('üé§ [VOICE INIT] Step 6: Setting up audio processing...');
      await this.setupAudioProcessing();
      console.log('üé§ [VOICE INIT] Audio processing set up successfully');
      
      this.isConnected = true;
      console.log('üé§ [VOICE INIT] ‚úÖ Voice Mode connected successfully for –ê–ª–µ—Å—è');
      
      if (this.onStatusChange) {
        this.onStatusChange('connected');
      }
      
    } catch (error) {
      console.error("üé§ [VOICE INIT] ‚ùå Failed to initialize –ê–ª–µ—Å—è audio chat:", error);
      console.error("üé§ [VOICE INIT] Error details:", {
        name: error.name,
        message: error.message,
        stack: error.stack
      });
      if (this.onError) {
        this.onError(error.message);
      }
      throw error;
    }
  }

  setupEventHandlers() {
    console.log('üé§ [EVENT HANDLERS] Setting up event handlers...');
    
    // Handle errors
    this.client.on('error', (event) => {
      console.error('üé§ [EVENT HANDLERS] ‚ùå RealtimeClient error:', event);
      console.error('üé§ [EVENT HANDLERS] Error details:', {
        type: event.type,
        error: event.error,
        message: event.message
      });
      if (this.onError) {
        this.onError(event.error?.message || 'Connection error');
      }
    });

    // Handle conversation updates
    this.client.on('conversation.updated', ({ item, delta }) => {
      console.log('üé§ [EVENT HANDLERS] üìù Conversation updated:', {
        itemType: item.type,
        itemRole: item.role,
        itemStatus: item.status,
        hasDelta: !!delta,
        deltaType: delta ? Object.keys(delta) : null
      });
      
      if (item.type === 'message' && item.role === 'assistant') {
        console.log('üé§ [EVENT HANDLERS] ü§ñ Assistant message received:', item.content);
        if (this.onMessage) {
          this.onMessage(item.content?.[0]?.text || '');
        }
      }
    });

    // Handle conversation interruption
    this.client.on('conversation.interrupted', () => {
      console.log('üé§ [EVENT HANDLERS] ‚è∏Ô∏è Conversation interrupted by user');
    });

    // Handle item completion
    this.client.on('conversation.item.completed', ({ item }) => {
      console.log('üé§ [EVENT HANDLERS] ‚úÖ Item completed:', {
        type: item.type,
        role: item.role,
        status: item.status
      });
      if (item.type === 'message' && item.role === 'assistant') {
        console.log('üé§ [EVENT HANDLERS] ü§ñ Assistant message completed');
        if (this.onStatusChange) {
          this.onStatusChange('ready');
        }
      }
    });

    // Handle realtime events
    this.client.on('realtime.event', ({ time, source, event }) => {
      console.log('üé§ [EVENT HANDLERS] üîÑ Realtime event:', {
        time,
        source,
        eventType: event.type,
        event: event
      });
    });

    console.log('üé§ [EVENT HANDLERS] ‚úÖ Event handlers set up successfully');
  }

  async setupAudioProcessing() {
    try {
      console.log('üé§ [AUDIO SETUP] Starting audio processing setup...');
      
      // Check if getUserMedia is available
      if (!navigator.mediaDevices || !navigator.mediaDevices.getUserMedia) {
        throw new Error('getUserMedia is not supported in this browser');
      }
      
      console.log('üé§ [AUDIO SETUP] Requesting microphone access...');
      // Get user media with proper audio constraints
      this.mediaStream = await navigator.mediaDevices.getUserMedia({
        audio: {
          sampleRate: 16000,
          channelCount: 1,
          echoCancellation: true,
          noiseSuppression: true,
          autoGainControl: true
        }
      });
      
      console.log('üé§ [AUDIO SETUP] ‚úÖ Microphone access granted');
      console.log('üé§ [AUDIO SETUP] Media stream tracks:', this.mediaStream.getTracks().length);
      console.log('üé§ [AUDIO SETUP] Audio track settings:', this.mediaStream.getAudioTracks()[0]?.getSettings());

      // Set up AudioContext for processing
      console.log('üé§ [AUDIO SETUP] Creating AudioContext...');
      this.audioContext = new (window.AudioContext || window.webkitAudioContext)({
        sampleRate: 16000
      });
      
      console.log('üé§ [AUDIO SETUP] AudioContext state:', this.audioContext.state);
      console.log('üé§ [AUDIO SETUP] AudioContext sample rate:', this.audioContext.sampleRate);

      // Create audio source from microphone
      console.log('üé§ [AUDIO SETUP] Creating audio source...');
      const source = this.audioContext.createMediaStreamSource(this.mediaStream);
      
      // Create ScriptProcessorNode for audio processing
      console.log('üé§ [AUDIO SETUP] Creating ScriptProcessorNode...');
      const processor = this.audioContext.createScriptProcessor(4096, 1, 1);
      
      let audioChunkCount = 0;
      processor.onaudioprocess = (event) => {
        if (this.isConnected && this.client) {
          const inputBuffer = event.inputBuffer;
          const inputData = inputBuffer.getChannelData(0);
          
          // Convert Float32Array to Int16Array
          const int16Data = new Int16Array(inputData.length);
          for (let i = 0; i < inputData.length; i++) {
            int16Data[i] = Math.max(-32768, Math.min(32767, inputData[i] * 32768));
          }
          
          // Log every 10th chunk to avoid spam
          audioChunkCount++;
          if (audioChunkCount % 10 === 0) {
            console.log('üé§ [AUDIO PROCESSING] Sending audio chunk #' + audioChunkCount, {
              dataLength: int16Data.length,
              sampleRate: inputBuffer.sampleRate,
              duration: inputBuffer.duration
            });
          }
          
          // Send audio data to Realtime API
          try {
            this.client.appendInputAudio(int16Data);
          } catch (error) {
            console.error('üé§ [AUDIO PROCESSING] Error sending audio:', error);
          }
        }
      };
      
      console.log('üé§ [AUDIO SETUP] Connecting audio nodes...');
      source.connect(processor);
      processor.connect(this.audioContext.destination);
      
      console.log('üé§ [AUDIO SETUP] ‚úÖ Audio processing setup complete');
      console.log('üé§ [AUDIO SETUP] Audio graph connected successfully');
      
    } catch (error) {
      console.error('üé§ [AUDIO SETUP] ‚ùå Error setting up audio processing:', error);
      console.error('üé§ [AUDIO SETUP] Error details:', {
        name: error.name,
        message: error.message,
        stack: error.stack
      });
      throw error;
    }
  }

  // Send a text message
  sendMessage(text) {
    console.log('üé§ [VOICE ACTIONS] üì§ Sending text message:', text);
    if (this.client && this.isConnected) {
      try {
        this.client.sendUserMessageContent([{ type: 'input_text', text: text }]);
        console.log('üé§ [VOICE ACTIONS] ‚úÖ Text message sent successfully');
      } catch (error) {
        console.error('üé§ [VOICE ACTIONS] ‚ùå Error sending text message:', error);
      }
    } else {
      console.warn('üé§ [VOICE ACTIONS] ‚ö†Ô∏è Cannot send message - client not connected');
    }
  }

  // Start listening (trigger response)
  startListening() {
    console.log('üé§ [VOICE ACTIONS] üé§ Starting listening...');
    if (this.client && this.isConnected) {
      try {
        this.client.createResponse();
        console.log('üé§ [VOICE ACTIONS] ‚úÖ Response creation triggered');
      } catch (error) {
        console.error('üé§ [VOICE ACTIONS] ‚ùå Error starting response:', error);
      }
    } else {
      console.warn('üé§ [VOICE ACTIONS] ‚ö†Ô∏è Cannot start listening - client not connected');
    }
  }

  // Stop current response
  stopResponse() {
    console.log('üé§ [VOICE ACTIONS] ‚èπÔ∏è Stopping current response...');
    if (this.client && this.isConnected) {
      try {
        const items = this.client.conversation.getItems();
        console.log('üé§ [VOICE ACTIONS] Current conversation items:', items.length);
        const currentItem = items[items.length - 1];
        if (currentItem && currentItem.status === 'in_progress') {
          console.log('üé§ [VOICE ACTIONS] Cancelling response for item:', currentItem.id);
          this.client.cancelResponse(currentItem.id, 0);
          console.log('üé§ [VOICE ACTIONS] ‚úÖ Response cancelled');
        } else {
          console.log('üé§ [VOICE ACTIONS] No active response to cancel');
        }
      } catch (error) {
        console.error('üé§ [VOICE ACTIONS] ‚ùå Error stopping response:', error);
      }
    } else {
      console.warn('üé§ [VOICE ACTIONS] ‚ö†Ô∏è Cannot stop response - client not connected');
    }
  }
  
  disconnect() {
    this.isConnected = false;
    
    if (this.mediaStream) {
      this.mediaStream.getTracks().forEach(track => track.stop());
      this.mediaStream = null;
    }
    
    if (this.audioContext) {
      this.audioContext.close();
      this.audioContext = null;
    }
    
    if (this.client) {
      this.client.disconnect();
      this.client = null;
    }
    
    if (this.onStatusChange) {
      this.onStatusChange('disconnected');
    }
  }
}

function App() {
  const [messages, setMessages] = useState([]);
  const [inputMessage, setInputMessage] = useState('');
  const [isLoading, setIsLoading] = useState(false);
  const [sessionId] = useState(() => `session_${Date.now()}_${Math.random().toString(36).substr(2, 9)}`);
  const [isRecording, setIsRecording] = useState(false);
  const [voiceMode, setVoiceMode] = useState(false); // false = text/voice, true = realtime voice
  const [mediaRecorder, setMediaRecorder] = useState(null);
  const [recordedAudio, setRecordedAudio] = useState(null);
  const [isTranscribing, setIsTranscribing] = useState(false);
  const [voiceModeStatus, setVoiceModeStatus] = useState('disconnected'); // disconnected, connecting, connected, ready
  const [voiceChat, setVoiceChat] = useState(null);
  const [capabilities, setCapabilities] = useState({});
  const messagesEndRef = useRef(null);

  const scrollToBottom = () => {
    messagesEndRef.current?.scrollIntoView({ behavior: 'smooth' });
  };

  useEffect(() => {
    scrollToBottom();
  }, [messages]);

  useEffect(() => {
    // Load chat history and capabilities
    loadChatHistory();
    loadCapabilities();
  }, []);

  const loadCapabilities = async () => {
    try {
      const response = await fetch(`${BACKEND_URL}/api/capabilities`);
      if (response.ok) {
        const data = await response.json();
        setCapabilities(data);
        console.log('Backend capabilities:', data);
      }
    } catch (error) {
      console.error('Error loading capabilities:', error);
    }
  };

  const loadChatHistory = async () => {
    try {
      const response = await fetch(`${BACKEND_URL}/api/history/${sessionId}`);
      if (response.ok) {
        const data = await response.json();
        setMessages(data.messages || []);
      }
    } catch (error) {
      console.error('Error loading chat history:', error);
    }
  };

  const sendMessage = async (message = inputMessage) => {
    if (!message.trim()) return;

    const userMessage = {
      id: Date.now().toString(),
      content: message,
      role: 'user',
      timestamp: new Date().toISOString()
    };

    setMessages(prev => [...prev, userMessage]);
    setInputMessage('');
    setIsLoading(true);

    try {
      const response = await fetch(`${BACKEND_URL}/api/chat`, {
        method: 'POST',
        headers: {
          'Content-Type': 'application/json',
        },
        body: JSON.stringify({
          session_id: sessionId,
          message: message
        })
      });

      if (response.ok) {
        const data = await response.json();
        const assistantMessage = {
          id: data.message_id,
          content: data.response,
          role: 'assistant',
          timestamp: new Date().toISOString()
        };
        setMessages(prev => [...prev, assistantMessage]);
      } else {
        throw new Error('Failed to send message');
      }
    } catch (error) {
      console.error('Error sending message:', error);
      const errorMessage = {
        id: Date.now().toString(),
        content: '–ò–∑–≤–∏–Ω–∏—Ç–µ, –ø—Ä–æ–∏–∑–æ—à–ª–∞ –æ—à–∏–±–∫–∞ –ø—Ä–∏ –æ—Ç–ø—Ä–∞–≤–∫–µ —Å–æ–æ–±—â–µ–Ω–∏—è.',
        role: 'assistant',
        timestamp: new Date().toISOString()
      };
      setMessages(prev => [...prev, errorMessage]);
    } finally {
      setIsLoading(false);
    }
  };

  const handleKeyPress = (e) => {
    if (e.key === 'Enter' && !e.shiftKey) {
      e.preventDefault();
      sendMessage();
    }
  };

  const startRecording = async () => {
    try {
      const stream = await navigator.mediaDevices.getUserMedia({ 
        audio: {
          sampleRate: 16000,
          channelCount: 1,
          echoCancellation: true,
          noiseSuppression: true
        }
      });
      
      const recorder = new MediaRecorder(stream, {
        mimeType: 'audio/webm;codecs=opus'
      });
      
      const audioChunks = [];
      
      recorder.ondataavailable = (event) => {
        if (event.data.size > 0) {
          audioChunks.push(event.data);
        }
      };
      
      recorder.onstop = async () => {
        const audioBlob = new Blob(audioChunks, { type: 'audio/webm' });
        setRecordedAudio(audioBlob);
        
        // Stop all audio tracks
        stream.getTracks().forEach(track => track.stop());
        
        // Transcribe audio
        await transcribeAudio(audioBlob);
      };
      
      recorder.start();
      setMediaRecorder(recorder);
      setIsRecording(true);
      console.log('Starting voice recording...');
      
    } catch (error) {
      console.error('Error accessing microphone:', error);
      alert('–û—à–∏–±–∫–∞ –¥–æ—Å—Ç—É–ø–∞ –∫ –º–∏–∫—Ä–æ—Ñ–æ–Ω—É. –ü–æ–∂–∞–ª—É–π—Å—Ç–∞, —Ä–∞–∑—Ä–µ—à–∏—Ç–µ –¥–æ—Å—Ç—É–ø –∫ –º–∏–∫—Ä–æ—Ñ–æ–Ω—É.');
    }
  };

  const stopRecording = () => {
    if (mediaRecorder && mediaRecorder.state === 'recording') {
      mediaRecorder.stop();
      setIsRecording(false);
      console.log('Stopping voice recording...');
    }
  };

  const transcribeAudio = async (audioBlob) => {
    setIsTranscribing(true);
    
    try {
      const formData = new FormData();
      formData.append('file', audioBlob, 'recording.webm');
      
      const response = await fetch(`${BACKEND_URL}/api/transcribe`, {
        method: 'POST',
        body: formData
      });
      
      if (response.ok) {
        const data = await response.json();
        const transcription = data.transcription;
        
        if (transcription && transcription.trim()) {
          // Set the transcribed text as input and send it
          setInputMessage(transcription);
          setTimeout(() => {
            sendMessage(transcription);
          }, 100);
        } else {
          console.warn('Empty transcription received');
          alert('–ù–µ —É–¥–∞–ª–æ—Å—å —Ä–∞—Å–ø–æ–∑–Ω–∞—Ç—å —Ä–µ—á—å. –ü–æ–ø—Ä–æ–±—É–π—Ç–µ –µ—â–µ —Ä–∞–∑.');
        }
      } else {
        const errorData = await response.json().catch(() => ({}));
        console.error('Transcription failed:', errorData);
        alert('–û—à–∏–±–∫–∞ –ø—Ä–∏ —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏–∏ —Ä–µ—á–∏. –ü–æ–ø—Ä–æ–±—É–π—Ç–µ –µ—â–µ —Ä–∞–∑.');
      }
    } catch (error) {
      console.error('Error transcribing audio:', error);
      alert('–û—à–∏–±–∫–∞ –ø—Ä–∏ –æ—Ç–ø—Ä–∞–≤–∫–µ –∞—É–¥–∏–æ. –ü—Ä–æ–≤–µ—Ä—å—Ç–µ —Å–æ–µ–¥–∏–Ω–µ–Ω–∏–µ —Å –∏–Ω—Ç–µ—Ä–Ω–µ—Ç–æ–º.');
    } finally {
      setIsTranscribing(false);
    }
  };

  const toggleVoiceMode = () => {
    setVoiceMode(!voiceMode);
    
    // Disconnect existing voice chat when switching modes
    if (voiceChat && voiceModeStatus !== 'disconnected') {
      disconnectVoiceMode();
    }
  };

  const connectVoiceMode = async () => {
    console.log('üé§ [CONNECT VOICE] Starting voice mode connection...');
    console.log('üé§ [CONNECT VOICE] Capabilities:', capabilities);
    
    if (!capabilities.voice_mode_available) {
      console.error('üé§ [CONNECT VOICE] ‚ùå Voice Mode not available');
      alert('Voice Mode –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω. –ü—Ä–æ–≤–µ—Ä—å—Ç–µ –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ —Å–µ—Ä–≤–µ—Ä–∞.');
      return;
    }
    
    console.log('üé§ [CONNECT VOICE] Setting status to connecting...');
    setVoiceModeStatus('connecting');
    
    try {
      console.log('üé§ [CONNECT VOICE] Creating RealtimeAudioChat instance...');
      const voiceChat = new RealtimeAudioChat();
      
      // Set up event handlers
      console.log('üé§ [CONNECT VOICE] Setting up event handlers...');
      voiceChat.onStatusChange = (status) => {
        console.log('üé§ [CONNECT VOICE] Status changed:', status);
        setVoiceModeStatus(status);
        if (status === 'connected') {
          console.log('üé§ [CONNECT VOICE] ‚úÖ Voice chat connected, setting instance');
          setVoiceChat(voiceChat);
        }
      };
      
      voiceChat.onError = (error) => {
        console.error('üé§ [CONNECT VOICE] ‚ùå Voice mode error:', error);
        alert(`–û—à–∏–±–∫–∞ –≥–æ–ª–æ—Å–æ–≤–æ–≥–æ —Ä–µ–∂–∏–º–∞: ${error}`);
        setVoiceModeStatus('disconnected');
      };
      
      voiceChat.onMessage = (text) => {
        console.log('üé§ [CONNECT VOICE] üìù Received message from voice chat:', text);
        // Add assistant message to chat
        const assistantMessage = {
          id: Date.now().toString(),
          content: text,
          role: 'assistant',
          timestamp: new Date().toISOString()
        };
        setMessages(prev => [...prev, assistantMessage]);
      };
      
      // Initialize voice chat
      console.log('üé§ [CONNECT VOICE] Initializing voice chat...');
      await voiceChat.init();
      console.log('üé§ [CONNECT VOICE] ‚úÖ Voice chat initialization completed');
      
    } catch (error) {
      console.error('üé§ [CONNECT VOICE] ‚ùå Voice mode connection failed:', error);
      console.error('üé§ [CONNECT VOICE] Error details:', {
        name: error.name,
        message: error.message,
        stack: error.stack
      });
      alert(`–ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–¥–∫–ª—é—á–∏—Ç—å—Å—è –∫ Voice Mode: ${error.message}`);
      setVoiceModeStatus('disconnected');
    }
  };

  const disconnectVoiceMode = () => {
    if (voiceChat) {
      voiceChat.disconnect();
      setVoiceChat(null);
    }
    setVoiceModeStatus('disconnected');
  };

  const playTTS = async (text) => {
    // Simple browser TTS for now
    if ('speechSynthesis' in window) {
      const utterance = new SpeechSynthesisUtterance(text);
      utterance.lang = 'ru-RU';
      window.speechSynthesis.speak(utterance);
    }
  };

  const getVoiceModeStatusText = () => {
    switch (voiceModeStatus) {
      case 'connecting': return '–ü–æ–¥–∫–ª—é—á–µ–Ω–∏–µ...';
      case 'connected': return '–ü–æ–¥–∫–ª—é—á–µ–Ω';
      case 'ready': return '–ì–æ—Ç–æ–≤ –∫ —Ä–∞–∑–≥–æ–≤–æ—Ä—É';
      case 'disconnected': return '–û—Ç–∫–ª—é—á–µ–Ω';
      default: return '–ù–µ–∏–∑–≤–µ—Å—Ç–Ω–æ';
    }
  };

  return (
    <div className="app">
      {/* Header with Belarus symbols */}
      <header className="app-header">
        <div className="header-content">
          <div className="symbols">
            <img 
              src="https://customer-assets.emergentagent.com/job_belarus-constitution/artifacts/zbmwau2o_1613443720_6-p-fon-dlya-prezentatsii-pro-belarus-10.jpg" 
              alt="–§–ª–∞–≥ –ë–µ–ª–∞—Ä—É—Å–∏" 
              className="flag"
            />
            <img 
              src="https://customer-assets.emergentagent.com/job_belarus-constitution/artifacts/nvezqned_Belarus_gerb_2021.jpg" 
              alt="–ì–µ—Ä–± –ë–µ–ª–∞—Ä—É—Å–∏" 
              className="coat-of-arms"
            />
          </div>
          <h1 className="title">AI-–∞—Å—Å–∏—Å—Ç–µ–Ω—Ç –ø–æ –ö–æ–Ω—Å—Ç–∏—Ç—É—Ü–∏–∏ –†–µ—Å–ø—É–±–ª–∏–∫–∏ –ë–µ–ª–∞—Ä—É—Å—å</h1>
          <div className="mode-toggle">
            <button 
              className={`mode-btn ${!voiceMode ? 'active' : ''}`}
              onClick={() => setVoiceMode(false)}
            >
              –¢–µ–∫—Å—Ç/–ì–æ–ª–æ—Å
            </button>
            <button 
              className={`mode-btn ${voiceMode ? 'active' : ''}`}
              onClick={toggleVoiceMode}
            >
              Voice Mode
            </button>
          </div>
        </div>
      </header>

      <main className="main-content">
        {/* Chat area */}
        <div className="chat-container">
          <div className="chat-messages">
            {messages.length === 0 && (
              <div className="welcome-message">
                <p>–î–æ–±—Ä–æ –ø–æ–∂–∞–ª–æ–≤–∞—Ç—å! –ú–µ–Ω—è –∑–æ–≤—É—Ç <strong>–ê–ª–µ—Å—è</strong>, –∏ —è –ø–æ–º–æ–≥—É –≤–∞–º –ø–æ–ª—É—á–∏—Ç—å –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –ø–æ –ö–æ–Ω—Å—Ç–∏—Ç—É—Ü–∏–∏ –†–µ—Å–ø—É–±–ª–∏–∫–∏ –ë–µ–ª–∞—Ä—É—Å—å.</p>
                <p>–ó–∞–¥–∞–π—Ç–µ –≤–∞—à –≤–æ–ø—Ä–æ—Å —Ç–µ–∫—Å—Ç–æ–º –∏–ª–∏ –≥–æ–ª–æ—Å–æ–º, –∏ —è –æ—Ç–≤–µ—á—É —Å–æ–≥–ª–∞—Å–Ω–æ –ö–æ–Ω—Å—Ç–∏—Ç—É—Ü–∏–∏ –†–ë —Ä–µ–¥–∞–∫—Ü–∏–∏ 2022 –≥–æ–¥–∞.</p>
                {voiceMode && (
                  <p>üé§ <strong>Voice Mode</strong> - —Ä–µ–∂–∏–º –≥–æ–ª–æ—Å–æ–≤–æ–≥–æ –æ–±—â–µ–Ω–∏—è –≤ —Ä–µ–∞–ª—å–Ω–æ–º –≤—Ä–µ–º–µ–Ω–∏ —Å –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç—å—é –ø–µ—Ä–µ–±–∏–≤–∞–Ω–∏—è.</p>
                )}
              </div>
            )}
            
            {messages.map((message) => (
              <div key={message.id} className={`message ${message.role}`}>
                <div className="message-content">
                  <span className="message-text">{message.content}</span>
                  {message.role === 'assistant' && (
                    <button 
                      className="tts-btn"
                      onClick={() => playTTS(message.content)}
                      title="–û–∑–≤—É—á–∏—Ç—å –æ—Ç–≤–µ—Ç"
                    >
                      üîä
                    </button>
                  )}
                </div>
                <div className="message-time">
                  {new Date(message.timestamp).toLocaleTimeString('ru-RU')}
                </div>
              </div>
            ))}
            
            {(isLoading || isTranscribing) && (
              <div className="message assistant">
                <div className="message-content loading">
                  <span>{isTranscribing ? '–†–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏–µ —Ä–µ—á–∏...' : '–ê—Å—Å–∏—Å—Ç–µ–Ω—Ç –¥—É–º–∞–µ—Ç...'}</span>
                  <div className="loading-dots">
                    <span></span>
                    <span></span>
                    <span></span>
                  </div>
                </div>
              </div>
            )}
            <div ref={messagesEndRef} />
          </div>

          {/* Input area */}
          {!voiceMode ? (
            <div className="chat-input">
              <div className="input-container">
                <textarea
                  value={inputMessage}
                  onChange={(e) => setInputMessage(e.target.value)}
                  onKeyPress={handleKeyPress}
                  placeholder="–ó–∞–¥–∞–π—Ç–µ –≤–∞—à –≤–æ–ø—Ä–æ—Å –ø–æ –ö–æ–Ω—Å—Ç–∏—Ç—É—Ü–∏–∏ –†–µ—Å–ø—É–±–ª–∏–∫–∏ –ë–µ–ª–∞—Ä—É—Å—å..."
                  disabled={isLoading || isTranscribing}
                  rows="2"
                />
                <div className="input-buttons">
                  <button
                    className={`voice-btn ${isRecording ? 'recording' : ''}`}
                    onMouseDown={startRecording}
                    onMouseUp={stopRecording}
                    onTouchStart={startRecording}
                    onTouchEnd={stopRecording}
                    disabled={isLoading || isTranscribing}
                    title="–£–¥–µ—Ä–∂–∏–≤–∞–π—Ç–µ –¥–ª—è –∑–∞–ø–∏—Å–∏ –≥–æ–ª–æ—Å–∞"
                  >
                    {isRecording ? 'üî¥' : 'üé§'}
                  </button>
                  <button
                    className="send-btn"
                    onClick={() => sendMessage()}
                    disabled={isLoading || !inputMessage.trim() || isTranscribing}
                  >
                    –û—Ç–ø—Ä–∞–≤–∏—Ç—å
                  </button>
                </div>
              </div>
              {isRecording && (
                <div className="recording-indicator">
                  üî¥ –ó–∞–ø–∏—Å—å... –û—Ç–ø—É—Å—Ç–∏—Ç–µ –∫–Ω–æ–ø–∫—É —á—Ç–æ–±—ã –æ—Ç–ø—Ä–∞–≤–∏—Ç—å
                </div>
              )}
            </div>
          ) : (
            <div className="voice-mode-controls">
              <div className="voice-status">
                <p>–†–µ–∂–∏–º –≥–æ–ª–æ—Å–æ–≤–æ–≥–æ –æ–±—â–µ–Ω–∏—è –≤ —Ä–µ–∞–ª—å–Ω–æ–º –≤—Ä–µ–º–µ–Ω–∏</p>
                <div className={`status-indicator ${voiceModeStatus}`}>
                  <span className="status-dot"></span>
                  –°—Ç–∞—Ç—É—Å: {getVoiceModeStatusText()}
                </div>
              </div>
              
              {voiceModeStatus === 'disconnected' && (
                <button 
                  className="voice-connect-btn"
                  onClick={connectVoiceMode}
                  disabled={!capabilities.voice_mode_available}
                >
                  {capabilities.voice_mode_available ? '–ü–æ–¥–∫–ª—é—á–∏—Ç—å—Å—è –∫ –≥–æ–ª–æ—Å–æ–≤–æ–º—É —á–∞—Ç—É' : 'Voice Mode –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω'}
                </button>
              )}
              
              {voiceModeStatus === 'connecting' && (
                <div className="voice-connecting">
                  <div className="loading-dots">
                    <span></span>
                    <span></span>
                    <span></span>
                  </div>
                  <p>–ü–æ–¥–∫–ª—é—á–µ–Ω–∏–µ –∫ Voice Mode...</p>
                </div>
              )}
              
              {(voiceModeStatus === 'connected' || voiceModeStatus === 'ready') && (
                <div className="voice-active">
                  <div className="voice-indicator">
                    üé§ <strong>–ì–æ–≤–æ—Ä–∏—Ç–µ!</strong> –Ø —Å–ª—É—à–∞—é...
                  </div>
                  <div className="voice-controls">
                    <button 
                      className="voice-listen-btn"
                      onClick={() => voiceChat?.startListening()}
                      disabled={voiceModeStatus !== 'ready'}
                    >
                      {voiceModeStatus === 'ready' ? 'üé§ –ù–∞—á–∞—Ç—å —Ä–∞–∑–≥–æ–≤–æ—Ä' : '‚è≥ –û–±—Ä–∞–±–æ—Ç–∫–∞...'}
                    </button>
                    <button 
                      className="voice-stop-btn"
                      onClick={() => voiceChat?.stopResponse()}
                      disabled={voiceModeStatus === 'ready'}
                    >
                      ‚èπÔ∏è –û—Å—Ç–∞–Ω–æ–≤–∏—Ç—å
                    </button>
                    <button 
                      className="voice-disconnect-btn"
                      onClick={disconnectVoiceMode}
                    >
                      ‚ùå –ó–∞–≤–µ—Ä—à–∏—Ç—å —Ä–∞–∑–≥–æ–≤–æ—Ä
                    </button>
                  </div>
                  <p className="voice-hint">
                    üí° –ì–æ–≤–æ—Ä–∏—Ç–µ –µ—Å—Ç–µ—Å—Ç–≤–µ–Ω–Ω–æ - —è –±—É–¥—É –æ—Ç–≤–µ—á–∞—Ç—å –≥–æ–ª–æ—Å–æ–º
                  </p>
                </div>
              )}
            </div>
          )}
        </div>

        {/* Avatar */}
        <div className="avatar-container">
          <img 
            src="https://customer-assets.emergentagent.com/job_belarus-constitution/artifacts/mqexhzvw_d3788255-d883-47b1-837f-751a2e82c62b.png" 
            alt="–ê—Å—Å–∏—Å—Ç–µ–Ω—Ç" 
            className="avatar"
          />
        </div>
      </main>
    </div>
  );
}

export default App;