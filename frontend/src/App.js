import React, { useState, useEffect, useRef } from 'react';
import './App.css';

const BACKEND_URL = 'http://localhost:8000';
const VERSION = '2.0.0'; // Force cache refresh

// Voice Mode WebSocket Class
class RealtimeAudioChat {
  constructor({
    backendUrl,
    voice,
    model,
    instructions,
  }) {
    this.websocket = null;
    this.playbackContext = null;
    this.playbackTime = 0;
    this.websocketUrl = null;
    this.sessionModel = model || "gpt-4o-realtime-preview-latest";
    this.backendUrl = backendUrl;
    this.voiceName = voice || "verse";
    this.instructions = instructions || null;
    this.onStatusChange = null;
    this.onError = null;
    this.localStream = null;
    this.audioContext = null;
    this.inputSource = null;
    this.processorNode = null;
    this.isRecording = false;
    this.clientSecret = null;
    this.pendingCommit = false;
    this.lastAudioTimestamp = 0;
    this.commitTimer = null;
    this.silenceThreshold = 0.01;
  }

  async init() {
    try {
      console.log('Initializing Voice Mode for –ê–ª–µ—Å—è... (v2.0.0 - WebSocket)');
      
      // Get session from backend
      const tokenResponse = await fetch(`${this.backendUrl}/api/voice/realtime/session`, {
        method: "POST",
        headers: {
          "Content-Type": "application/json"
        },
        body: JSON.stringify({
          voice: this.voiceName,
          model: this.sessionModel,
          instructions: this.instructions || undefined,
        })
      });

      if (!tokenResponse.ok) {
        throw new Error(`Session request failed: ${tokenResponse.status}`);
      }
      
      const data = await tokenResponse.json();
      const clientSecret =
        (data.client_secret && data.client_secret.value) ||
        data.client_secret_value;
      if (!data.websocket_url || !clientSecret) {
        throw new Error("Failed to get Voice Mode credentials");
      }

      this.websocketUrl = data.websocket_url;
      this.sessionModel = data.model || this.sessionModel;
      this.instructions = data.instructions || this.instructions;
      this.clientSecret = clientSecret;

      console.log('Voice Mode session created successfully');

      // Setup audio playback context
      this.setupPlaybackContext();

      // Setup microphone access
      await this.setupLocalAudio();

      // Connect to WebSocket
      await this.connectWebSocket();

      if (this.onStatusChange) {
        this.onStatusChange('connected');
      }

    } catch (error) {
      console.error("Failed to initialize –ê–ª–µ—Å—è audio chat:", error);
      if (this.onError) {
        this.onError(error.message);
      }
      throw error;
    }
  }

  setupPlaybackContext() {
    if (!this.playbackContext) {
      const AudioContextClass = window.AudioContext || window.webkitAudioContext;
      try {
        this.playbackContext = new AudioContextClass({ sampleRate: 24000 });
      } catch (error) {
        console.warn('Falling back to default AudioContext sampleRate:', error);
        this.playbackContext = new AudioContextClass();
      }
      this.playbackTime = 0;
    }
  }

  async setupLocalAudio() {
    this.localStream = await navigator.mediaDevices.getUserMedia({
      audio: {
        echoCancellation: true,
        noiseSuppression: true,
        autoGainControl: true
      }
    });

    const audioTracks = this.localStream.getAudioTracks();
    if (!audioTracks.length) {
      throw new Error('–ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å –¥–æ—Å—Ç—É–ø –∫ –º–∏–∫—Ä–æ—Ñ–æ–Ω—É');
    }

    const AudioContextClass = window.AudioContext || window.webkitAudioContext;
    this.audioContext = new AudioContextClass();
    await this.audioContext.resume();

    this.inputSource = this.audioContext.createMediaStreamSource(this.localStream);
    this.processorNode = this.audioContext.createScriptProcessor(4096, 1, 1);

    const gainNode = this.audioContext.createGain();
    gainNode.gain.value = 0;

    this.processorNode.onaudioprocess = (event) => {
      if (!this.isRecording || !this.websocket || this.websocket.readyState !== WebSocket.OPEN) {
        return;
      }

      const inputBuffer = event.inputBuffer;
      const channelData = inputBuffer.getChannelData(0);
      const rms = this.calculateRMS(channelData);

      if (rms < this.silenceThreshold) {
        return;
      }

      const downsampled = this.downsampleBuffer(channelData, inputBuffer.sampleRate, 24000);
      if (!downsampled.length) {
        return;
      }

      const pcm = this.floatTo16BitPCM(downsampled);
      const base64Audio = this.arrayBufferToBase64(pcm.buffer);

      this.websocket.send(JSON.stringify({
        type: 'input_audio_buffer.append',
        audio: base64Audio,
      }));

      this.lastAudioTimestamp = Date.now();
      this.pendingCommit = true;
    };

    this.inputSource.connect(this.processorNode);
    this.processorNode.connect(gainNode);
    gainNode.connect(this.audioContext.destination);
  }

  async connectWebSocket() {
    return new Promise((resolve, reject) => {
      try {
        const protocols = [
          'realtime',
          `openai-insecure-api-key.${this.clientSecret}`,
          'openai-beta.realtime-v1'
        ];
        this.websocket = new WebSocket(this.websocketUrl, protocols);

        this.websocket.onopen = () => {
          console.log('WebSocket connected to Realtime API');

          // Send session configuration
          this.websocket.send(JSON.stringify({
            type: 'session.update',
            session: {
              instructions: this.instructions,
              voice: this.voiceName,
              model: this.sessionModel
            }
          }));

          // Start audio recording
          this.startRecording();

          resolve();
        };

        this.websocket.onmessage = (event) => {
          try {
            const data = JSON.parse(event.data);
            this.handleWebSocketMessage(data);
          } catch (error) {
            console.error('Error parsing WebSocket message:', error);
          }
        };

        this.websocket.onerror = (error) => {
          console.error('WebSocket error:', error);
          if (this.onError) {
            this.onError('WebSocket connection failed');
          }
          reject(error);
        };

        this.websocket.onclose = () => {
          console.log('WebSocket disconnected');
          if (this.onStatusChange) {
            this.onStatusChange('disconnected');
          }
          this.stopRecording();
        };

      } catch (error) {
        reject(error);
      }
    });
  }

  handleWebSocketMessage(data) {
    console.log('Received WebSocket message:', data);

    switch (data.type) {
      case 'response.audio.delta':
        if (data.delta) {
          this.playbackAudioDelta(data.delta);
        }
        break;

      case 'response.done':
        console.log('Response completed');
        break;

      case 'response.error':
        if (data.error) {
          console.error('Realtime API response error:', data.error);
        }
        break;

      case 'error':
        console.error('Realtime API error:', data.error);
        if (this.onError) {
          this.onError(data.error.message || 'Unknown error');
        }
        break;
        
      default:
        console.log('Unknown message type:', data.type);
    }
  }

  startRecording() {
    if (this.isRecording) {
      return;
    }

    if (this.audioContext && this.audioContext.state === 'suspended') {
      this.audioContext.resume().catch((error) => {
        console.error('Failed to resume audio context:', error);
      });
    }

    this.isRecording = true;
    this.lastAudioTimestamp = Date.now();
    console.log('Started realtime audio streaming');

    if (!this.commitTimer) {
      this.commitTimer = window.setInterval(() => {
        if (
          this.pendingCommit &&
          Date.now() - this.lastAudioTimestamp > 600 &&
          this.websocket &&
          this.websocket.readyState === WebSocket.OPEN
        ) {
          this.websocket.send(JSON.stringify({ type: 'input_audio_buffer.commit' }));
          this.websocket.send(JSON.stringify({ type: 'response.create' }));
          this.pendingCommit = false;
        }
      }, 300);
    }

    if (this.onStatusChange) {
      this.onStatusChange('ready');
    }
  }

  stopRecording() {
    if (!this.isRecording) {
      return;
    }

    this.isRecording = false;
    this.pendingCommit = false;
    console.log('Stopped realtime audio streaming');

    if (this.commitTimer) {
      clearInterval(this.commitTimer);
      this.commitTimer = null;
    }

    if (this.websocket && this.websocket.readyState === WebSocket.OPEN) {
      this.websocket.send(JSON.stringify({ type: 'input_audio_buffer.commit' }));
      this.websocket.send(JSON.stringify({ type: 'response.create' }));
    }
  }

  calculateRMS(buffer) {
    let sum = 0;
    for (let i = 0; i < buffer.length; i++) {
      sum += buffer[i] * buffer[i];
    }
    return Math.sqrt(sum / buffer.length);
  }

  downsampleBuffer(buffer, sampleRate, outSampleRate) {
    if (outSampleRate === sampleRate) {
      return buffer;
    }

    const sampleRateRatio = sampleRate / outSampleRate;
    const newLength = Math.round(buffer.length / sampleRateRatio);
    const result = new Float32Array(newLength);
    let offsetResult = 0;
    let offsetBuffer = 0;

    while (offsetResult < result.length) {
      const nextOffsetBuffer = Math.round((offsetResult + 1) * sampleRateRatio);
      let accum = 0;
      let count = 0;
      for (let i = offsetBuffer; i < nextOffsetBuffer && i < buffer.length; i++) {
        accum += buffer[i];
        count++;
      }
      result[offsetResult] = accum / (count || 1);
      offsetResult++;
      offsetBuffer = nextOffsetBuffer;
    }

    return result;
  }

  floatTo16BitPCM(buffer) {
    const length = buffer.length;
    const result = new Int16Array(length);
    for (let i = 0; i < length; i++) {
      const s = Math.max(-1, Math.min(1, buffer[i]));
      result[i] = s < 0 ? s * 0x8000 : s * 0x7fff;
    }
    return result;
  }

  arrayBufferToBase64(buffer) {
    let binary = '';
    const bytes = new Uint8Array(buffer);
    const chunkSize = 0x8000;
    for (let i = 0; i < bytes.length; i += chunkSize) {
      const chunk = bytes.subarray(i, i + chunkSize);
      binary += String.fromCharCode.apply(null, chunk);
    }
    return btoa(binary);
  }

  base64ToInt16(base64) {
    const binary = atob(base64);
    const buffer = new ArrayBuffer(binary.length);
    const bytes = new Uint8Array(buffer);
    for (let i = 0; i < binary.length; i++) {
      bytes[i] = binary.charCodeAt(i);
    }
    return new Int16Array(buffer);
  }

  playbackAudioDelta(base64Audio) {
    if (!this.playbackContext) {
      return;
    }

    if (this.playbackContext.state === 'suspended') {
      this.playbackContext.resume().catch((error) => {
        console.warn('Failed to resume playback context:', error);
      });
    }

    const int16Array = this.base64ToInt16(base64Audio);
    if (!int16Array.length) {
      return;
    }

    const floatArray = new Float32Array(int16Array.length);
    for (let i = 0; i < int16Array.length; i++) {
      floatArray[i] = int16Array[i] / 0x8000;
    }

    const audioBuffer = this.playbackContext.createBuffer(1, floatArray.length, 24000);
    audioBuffer.copyToChannel(floatArray, 0);

    const source = this.playbackContext.createBufferSource();
    source.buffer = audioBuffer;
    source.connect(this.playbackContext.destination);

    const startAt = Math.max(this.playbackContext.currentTime, this.playbackTime);
    source.start(startAt);
    this.playbackTime = startAt + audioBuffer.duration;
  }


  disconnect() {
    // Stop recording
    this.stopRecording();

    // Close WebSocket connection
    if (this.websocket) {
      this.websocket.close();
      this.websocket = null;
    }

    // Stop local audio stream
    if (this.localStream) {
      this.localStream.getTracks().forEach((track) => track.stop());
      this.localStream = null;
    }

    if (this.processorNode) {
      this.processorNode.disconnect();
      this.processorNode = null;
    }

    if (this.inputSource) {
      this.inputSource.disconnect();
      this.inputSource = null;
    }

    if (this.audioContext) {
      this.audioContext.close().catch(() => {});
      this.audioContext = null;
    }

    if (this.playbackContext) {
      this.playbackContext.close().catch(() => {});
      this.playbackContext = null;
      this.playbackTime = 0;
    }

    if (this.onStatusChange) {
      this.onStatusChange('disconnected');
    }
  }
}

function App() {
  const [messages, setMessages] = useState([]);
  const [inputMessage, setInputMessage] = useState('');
  const [isLoading, setIsLoading] = useState(false);
  const [sessionId] = useState(() => `session_${Date.now()}_${Math.random().toString(36).substr(2, 9)}`);
  const [isRecording, setIsRecording] = useState(false);
  const [voiceMode, setVoiceMode] = useState(false); // false = text/voice, true = realtime voice
  const [mediaRecorder, setMediaRecorder] = useState(null);
  const [recordedAudio, setRecordedAudio] = useState(null);
  const [isTranscribing, setIsTranscribing] = useState(false);
  const [voiceModeStatus, setVoiceModeStatus] = useState('disconnected'); // disconnected, connecting, connected, ready
  const [voiceChat, setVoiceChat] = useState(null);
  const [capabilities, setCapabilities] = useState({});
  const messagesEndRef = useRef(null);

  const scrollToBottom = () => {
    messagesEndRef.current?.scrollIntoView({ behavior: 'smooth' });
  };

  useEffect(() => {
    scrollToBottom();
  }, [messages]);

  useEffect(() => {
    // Load chat history and capabilities
    loadChatHistory();
    loadCapabilities();
  }, []);

  const loadCapabilities = async () => {
    try {
      const response = await fetch(`${BACKEND_URL}/api/capabilities`);
      if (response.ok) {
        const data = await response.json();
        setCapabilities(data);
        console.log('Backend capabilities:', data);
      }
    } catch (error) {
      console.error('Error loading capabilities:', error);
    }
  };

  const loadChatHistory = async () => {
    try {
      const response = await fetch(`${BACKEND_URL}/api/history/${sessionId}`);
      if (response.ok) {
        const data = await response.json();
        setMessages(data.messages || []);
      }
    } catch (error) {
      console.error('Error loading chat history:', error);
    }
  };

  const sendMessage = async (message = inputMessage) => {
    if (!message.trim()) return;

    const userMessage = {
      id: Date.now().toString(),
      content: message,
      role: 'user',
      timestamp: new Date().toISOString()
    };

    setMessages(prev => [...prev, userMessage]);
    setInputMessage('');
    setIsLoading(true);

    try {
      const response = await fetch(`${BACKEND_URL}/api/chat`, {
        method: 'POST',
        headers: {
          'Content-Type': 'application/json',
        },
        body: JSON.stringify({
          session_id: sessionId,
          message: message
        })
      });

      if (response.ok) {
        const data = await response.json();
        const assistantMessage = {
          id: data.message_id,
          content: data.response,
          role: 'assistant',
          timestamp: new Date().toISOString()
        };
        setMessages(prev => [...prev, assistantMessage]);
      } else {
        throw new Error('Failed to send message');
      }
    } catch (error) {
      console.error('Error sending message:', error);
      const errorMessage = {
        id: Date.now().toString(),
        content: '–ò–∑–≤–∏–Ω–∏—Ç–µ, –ø—Ä–æ–∏–∑–æ—à–ª–∞ –æ—à–∏–±–∫–∞ –ø—Ä–∏ –æ—Ç–ø—Ä–∞–≤–∫–µ —Å–æ–æ–±—â–µ–Ω–∏—è.',
        role: 'assistant',
        timestamp: new Date().toISOString()
      };
      setMessages(prev => [...prev, errorMessage]);
    } finally {
      setIsLoading(false);
    }
  };

  const handleKeyPress = (e) => {
    if (e.key === 'Enter' && !e.shiftKey) {
      e.preventDefault();
      sendMessage();
    }
  };

  const startRecording = async () => {
    try {
      const stream = await navigator.mediaDevices.getUserMedia({ 
        audio: {
          sampleRate: 16000,
          channelCount: 1,
          echoCancellation: true,
          noiseSuppression: true
        }
      });
      
      const recorder = new MediaRecorder(stream, {
        mimeType: 'audio/webm;codecs=opus'
      });
      
      const audioChunks = [];
      
      recorder.ondataavailable = (event) => {
        if (event.data.size > 0) {
          audioChunks.push(event.data);
        }
      };
      
      recorder.onstop = async () => {
        const audioBlob = new Blob(audioChunks, { type: 'audio/webm' });
        setRecordedAudio(audioBlob);
        
        // Stop all audio tracks
        stream.getTracks().forEach(track => track.stop());
        
        // Transcribe audio
        await transcribeAudio(audioBlob);
      };
      
      recorder.start();
      setMediaRecorder(recorder);
      setIsRecording(true);
      console.log('Starting voice recording...');
      
    } catch (error) {
      console.error('Error accessing microphone:', error);
      alert('–û—à–∏–±–∫–∞ –¥–æ—Å—Ç—É–ø–∞ –∫ –º–∏–∫—Ä–æ—Ñ–æ–Ω—É. –ü–æ–∂–∞–ª—É–π—Å—Ç–∞, —Ä–∞–∑—Ä–µ—à–∏—Ç–µ –¥–æ—Å—Ç—É–ø –∫ –º–∏–∫—Ä–æ—Ñ–æ–Ω—É.');
    }
  };

  const stopRecording = () => {
    if (mediaRecorder && mediaRecorder.state === 'recording') {
      mediaRecorder.stop();
      setIsRecording(false);
      console.log('Stopping voice recording...');
    }
  };

  const transcribeAudio = async (audioBlob) => {
    setIsTranscribing(true);
    
    try {
      const formData = new FormData();
      formData.append('file', audioBlob, 'recording.webm');
      
      const response = await fetch(`${BACKEND_URL}/api/transcribe`, {
        method: 'POST',
        body: formData
      });
      
      if (response.ok) {
        const data = await response.json();
        const transcription = data.transcription;
        
        if (transcription && transcription.trim()) {
          // Set the transcribed text as input and send it
          setInputMessage(transcription);
          setTimeout(() => {
            sendMessage(transcription);
          }, 100);
        } else {
          console.warn('Empty transcription received');
          alert('–ù–µ —É–¥–∞–ª–æ—Å—å —Ä–∞—Å–ø–æ–∑–Ω–∞—Ç—å —Ä–µ—á—å. –ü–æ–ø—Ä–æ–±—É–π—Ç–µ –µ—â–µ —Ä–∞–∑.');
        }
      } else {
        const errorData = await response.json().catch(() => ({}));
        console.error('Transcription failed:', errorData);
        alert('–û—à–∏–±–∫–∞ –ø—Ä–∏ —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏–∏ —Ä–µ—á–∏. –ü–æ–ø—Ä–æ–±—É–π—Ç–µ –µ—â–µ —Ä–∞–∑.');
      }
    } catch (error) {
      console.error('Error transcribing audio:', error);
      alert('–û—à–∏–±–∫–∞ –ø—Ä–∏ –æ—Ç–ø—Ä–∞–≤–∫–µ –∞—É–¥–∏–æ. –ü—Ä–æ–≤–µ—Ä—å—Ç–µ —Å–æ–µ–¥–∏–Ω–µ–Ω–∏–µ —Å –∏–Ω—Ç–µ—Ä–Ω–µ—Ç–æ–º.');
    } finally {
      setIsTranscribing(false);
    }
  };

  const toggleVoiceMode = () => {
    setVoiceMode(!voiceMode);
    
    // Disconnect existing voice chat when switching modes
    if (voiceChat && voiceModeStatus !== 'disconnected') {
      disconnectVoiceMode();
    }
  };

  const connectVoiceMode = async () => {
    if (!capabilities.voice_mode_available) {
      alert('Voice Mode –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω. –ü—Ä–æ–≤–µ—Ä—å—Ç–µ –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ —Å–µ—Ä–≤–µ—Ä–∞.');
      return;
    }

    setVoiceModeStatus('connecting');

    try {
      const newVoiceChat = new RealtimeAudioChat({
        backendUrl: BACKEND_URL,
        voice: capabilities.voice_name,
        model: capabilities.voice_model,
        instructions: capabilities.voice_instructions,
      });

      newVoiceChat.onStatusChange = (status) => {
        setVoiceModeStatus(status);
      };
      
      newVoiceChat.onError = (error) => {
        alert(`–û—à–∏–±–∫–∞ Voice Mode: ${error}`);
        setVoiceModeStatus('disconnected');
      };
      
      await newVoiceChat.init();
      setVoiceChat(newVoiceChat);
      
    } catch (error) {
      console.error('Voice mode connection failed:', error);
      alert('–ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–¥–∫–ª—é—á–∏—Ç—å—Å—è –∫ Voice Mode. –ü–æ–ø—Ä–æ–±—É–π—Ç–µ –µ—â–µ —Ä–∞–∑.');
      setVoiceModeStatus('disconnected');
    }
  };

  const disconnectVoiceMode = () => {
    if (voiceChat) {
      voiceChat.disconnect();
      setVoiceChat(null);
    }
    setVoiceModeStatus('disconnected');
  };

  const playTTS = async (text) => {
    // Simple browser TTS for now
    if ('speechSynthesis' in window) {
      const utterance = new SpeechSynthesisUtterance(text);
      utterance.lang = 'ru-RU';
      window.speechSynthesis.speak(utterance);
    }
  };

  const getVoiceModeStatusText = () => {
    switch (voiceModeStatus) {
      case 'connecting': return '–ü–æ–¥–∫–ª—é—á–µ–Ω–∏–µ...';
      case 'connected': return '–ü–æ–¥–∫–ª—é—á–µ–Ω';
      case 'ready': return '–ì–æ—Ç–æ–≤ –∫ —Ä–∞–∑–≥–æ–≤–æ—Ä—É';
      case 'disconnected': return '–û—Ç–∫–ª—é—á–µ–Ω';
      default: return '–ù–µ–∏–∑–≤–µ—Å—Ç–Ω–æ';
    }
  };

  return (
    <div className="app">
      {/* Header with Belarus symbols */}
      <header className="app-header">
        <div className="header-content">
          <div className="symbols">
            <img 
              src="https://customer-assets.emergentagent.com/job_belarus-constitution/artifacts/zbmwau2o_1613443720_6-p-fon-dlya-prezentatsii-pro-belarus-10.jpg" 
              alt="–§–ª–∞–≥ –ë–µ–ª–∞—Ä—É—Å–∏" 
              className="flag"
            />
            <img 
              src="https://customer-assets.emergentagent.com/job_belarus-constitution/artifacts/nvezqned_Belarus_gerb_2021.jpg" 
              alt="–ì–µ—Ä–± –ë–µ–ª–∞—Ä—É—Å–∏" 
              className="coat-of-arms"
            />
          </div>
          <h1 className="title">AI-–∞—Å—Å–∏—Å—Ç–µ–Ω—Ç –ø–æ –ö–æ–Ω—Å—Ç–∏—Ç—É—Ü–∏–∏ –†–µ—Å–ø—É–±–ª–∏–∫–∏ –ë–µ–ª–∞—Ä—É—Å—å</h1>
          <div className="mode-toggle">
            <button 
              className={`mode-btn ${!voiceMode ? 'active' : ''}`}
              onClick={() => setVoiceMode(false)}
            >
              –¢–µ–∫—Å—Ç/–ì–æ–ª–æ—Å
            </button>
            <button 
              className={`mode-btn ${voiceMode ? 'active' : ''}`}
              onClick={toggleVoiceMode}
            >
              Voice Mode
            </button>
          </div>
        </div>
      </header>

      <main className="main-content">
        {/* Chat area */}
        <div className="chat-container">
          <div className="chat-messages">
            {messages.length === 0 && (
              <div className="welcome-message">
                <p>–î–æ–±—Ä–æ –ø–æ–∂–∞–ª–æ–≤–∞—Ç—å! –ú–µ–Ω—è –∑–æ–≤—É—Ç <strong>–ê–ª–µ—Å—è</strong>, –∏ —è –ø–æ–º–æ–≥—É –≤–∞–º –ø–æ–ª—É—á–∏—Ç—å –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –ø–æ –ö–æ–Ω—Å—Ç–∏—Ç—É—Ü–∏–∏ –†–µ—Å–ø—É–±–ª–∏–∫–∏ –ë–µ–ª–∞—Ä—É—Å—å.</p>
                <p>–ó–∞–¥–∞–π—Ç–µ –≤–∞—à –≤–æ–ø—Ä–æ—Å —Ç–µ–∫—Å—Ç–æ–º –∏–ª–∏ –≥–æ–ª–æ—Å–æ–º, –∏ —è –æ—Ç–≤–µ—á—É —Å–æ–≥–ª–∞—Å–Ω–æ –ö–æ–Ω—Å—Ç–∏—Ç—É—Ü–∏–∏ –†–ë —Ä–µ–¥–∞–∫—Ü–∏–∏ 2022 –≥–æ–¥–∞.</p>
                {voiceMode && (
                  <p>üé§ <strong>Voice Mode</strong> - —Ä–µ–∂–∏–º –≥–æ–ª–æ—Å–æ–≤–æ–≥–æ –æ–±—â–µ–Ω–∏—è –≤ —Ä–µ–∞–ª—å–Ω–æ–º –≤—Ä–µ–º–µ–Ω–∏ —Å –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç—å—é –ø–µ—Ä–µ–±–∏–≤–∞–Ω–∏—è.</p>
                )}
              </div>
            )}
            
            {messages.map((message) => (
              <div key={message.id} className={`message ${message.role}`}>
                <div className="message-content">
                  <span className="message-text">{message.content}</span>
                  {message.role === 'assistant' && (
                    <button 
                      className="tts-btn"
                      onClick={() => playTTS(message.content)}
                      title="–û–∑–≤—É—á–∏—Ç—å –æ—Ç–≤–µ—Ç"
                    >
                      üîä
                    </button>
                  )}
                </div>
                <div className="message-time">
                  {new Date(message.timestamp).toLocaleTimeString('ru-RU')}
                </div>
              </div>
            ))}
            
            {(isLoading || isTranscribing) && (
              <div className="message assistant">
                <div className="message-content loading">
                  <span>{isTranscribing ? '–†–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏–µ —Ä–µ—á–∏...' : '–ê—Å—Å–∏—Å—Ç–µ–Ω—Ç –¥—É–º–∞–µ—Ç...'}</span>
                  <div className="loading-dots">
                    <span></span>
                    <span></span>
                    <span></span>
                  </div>
                </div>
              </div>
            )}
            <div ref={messagesEndRef} />
          </div>

          {/* Input area */}
          {!voiceMode ? (
            <div className="chat-input">
              <div className="input-container">
                <textarea
                  value={inputMessage}
                  onChange={(e) => setInputMessage(e.target.value)}
                  onKeyPress={handleKeyPress}
                  placeholder="–ó–∞–¥–∞–π—Ç–µ –≤–∞—à –≤–æ–ø—Ä–æ—Å –ø–æ –ö–æ–Ω—Å—Ç–∏—Ç—É—Ü–∏–∏ –†–µ—Å–ø—É–±–ª–∏–∫–∏ –ë–µ–ª–∞—Ä—É—Å—å..."
                  disabled={isLoading || isTranscribing}
                  rows="2"
                />
                <div className="input-buttons">
                  <button
                    className="send-btn"
                    onClick={() => sendMessage()}
                    disabled={isLoading || !inputMessage.trim() || isTranscribing}
                  >
                    –û—Ç–ø—Ä–∞–≤–∏—Ç—å
                  </button>
                </div>
              </div>
              {isRecording && (
                <div className="recording-indicator">
                  üî¥ –ó–∞–ø–∏—Å—å... –û—Ç–ø—É—Å—Ç–∏—Ç–µ –∫–Ω–æ–ø–∫—É —á—Ç–æ–±—ã –æ—Ç–ø—Ä–∞–≤–∏—Ç—å
                </div>
              )}
            </div>
          ) : (
            <div className="voice-mode-controls">
              <div className="voice-status">
                <p>–†–µ–∂–∏–º –≥–æ–ª–æ—Å–æ–≤–æ–≥–æ –æ–±—â–µ–Ω–∏—è –≤ —Ä–µ–∞–ª—å–Ω–æ–º –≤—Ä–µ–º–µ–Ω–∏</p>
                <div className={`status-indicator ${voiceModeStatus}`}>
                  <span className="status-dot"></span>
                  –°—Ç–∞—Ç—É—Å: {getVoiceModeStatusText()}
                </div>
              </div>
              
              {voiceModeStatus === 'disconnected' && (
                <button 
                  className="voice-connect-btn"
                  onClick={connectVoiceMode}
                  disabled={!capabilities.voice_mode_available}
                >
                  {capabilities.voice_mode_available ? '–ü–æ–¥–∫–ª—é—á–∏—Ç—å—Å—è –∫ –≥–æ–ª–æ—Å–æ–≤–æ–º—É —á–∞—Ç—É' : 'Voice Mode –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω'}
                </button>
              )}
              
              {voiceModeStatus === 'connecting' && (
                <div className="voice-connecting">
                  <div className="loading-dots">
                    <span></span>
                    <span></span>
                    <span></span>
                  </div>
                  <p>–ü–æ–¥–∫–ª—é—á–µ–Ω–∏–µ –∫ Voice Mode...</p>
                </div>
              )}
              
              {(voiceModeStatus === 'connected' || voiceModeStatus === 'ready') && (
                <div className="voice-active">
                  <div className="voice-indicator">
                    üé§ <strong>–ì–æ–≤–æ—Ä–∏—Ç–µ!</strong> –Ø —Å–ª—É—à–∞—é...
                  </div>
                  <button 
                    className="voice-disconnect-btn"
                    onClick={disconnectVoiceMode}
                  >
                    –ó–∞–≤–µ—Ä—à–∏—Ç—å —Ä–∞–∑–≥–æ–≤–æ—Ä
                  </button>
                  <p className="voice-hint">
                    üí° –í—ã –º–æ–∂–µ—Ç–µ –ø–µ—Ä–µ–±–∏–≤–∞—Ç—å –º–µ–Ω—è –≤ –ª—é–±–æ–π –º–æ–º–µ–Ω—Ç
                  </p>
                </div>
              )}
            </div>
          )}
        </div>

        {/* Avatar */}
        <div className="avatar-container">
          <img 
            src="https://customer-assets.emergentagent.com/job_belarus-constitution/artifacts/mqexhzvw_d3788255-d883-47b1-837f-751a2e82c62b.png" 
            alt="–ê—Å—Å–∏—Å—Ç–µ–Ω—Ç" 
            className="avatar"
          />
        </div>
      </main>
    </div>
  );
}

export default App;